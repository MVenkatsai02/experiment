# ğŸ¤– LLM-Based Retrieval-Augmented Generation (RAG) System

A smart AI-powered Retrieval-Augmented Generation (RAG) system that fetches relevant content from the internet, processes it, and generates answers using Google Gemini 1.5 Flash. Built with a Flask backend, Streamlit frontend, and powered by real-time web scraping and LLMs.

---

## ğŸ› ï¸ Features

âœ… Web search via Serper API  
âœ… Intelligent article scraping and summarization  
âœ… LLM-powered response generation using Gemini 1.5 Flash  
âœ… Flask backend API for processing and generation  
âœ… Streamlit UI for query input and response display  
âœ… Easy deployment to Render (backend) and Streamlit Cloud (frontend)  

---

## ğŸ“‚ Project Structure

```bash
experiment/
â”œâ”€â”€ app.py              # Flask backend
â”œâ”€â”€ utils.py            # Web search, scraping, LLM generation
â”œâ”€â”€ frontend.py              # Streamlit frontend
â”œâ”€â”€ requirements.txt        # Project dependencies
â”œâ”€â”€ .env                    # API keys (excluded from Git)
â”œâ”€â”€ .gitignore              # Ignore files
â””â”€â”€ README.md               # Project documentation
```

## ğŸš€ Installation & Setup

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/MVenkatsai02/experiment
cd multi-agent-ai-code-generator
```

### 2ï¸âƒ£ Set Up a Virtual Environment

```bash
python -m venv venv
source venv/bin/activate  # On Windows use `venv\Scripts\activate`
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### ğŸ” Environment Variables
 Create a .env file in the root directory:
 ```bash
GEMINI_API_KEY=your_gemini_1.5_flash_api_key
SERPER_API_KEY=your_serper_api_key
```

### ğŸ§ª Running Locally
ğŸ”¹ Run Flask Backend
```bash
python app.py
```
The backend will run at: http://localhost:5000/query

ğŸ”¹ Run Streamlit Frontend
In another terminal:
```bash
streamlit run app.py
```
Streamlit UI will be available at: http://localhost:8501

### ğŸŒ Deployment
âœ… Flask Backend on Render

1 Push the project to GitHub.

2 Go to Render.

3 Create a New Web Service â†’ Select your repo.

4 Set:

    Build Command: pip install -r requirements.txt

    Start Command: python app.py

    Environment: Python 3

    Environment Variables:

        GEMINI_API_KEY

        SERPER_API_KEY

5 Deploy and get your backend URL:
Example: https://rag-backend.onrender.com/query

### âœ… Streamlit Frontend on Streamlit Cloud
1 Push the repo to GitHub (with updated backend URL in frontend app.py).

2 Go to Streamlit Cloud.

3 Deploy your repo and select streamlit_app/app.py as the main file.

4 Done! Share your app link.

### ğŸ’¡ Example Usage
1 Open the deployed Streamlit app.

2 Enter a query like: AI in education.

3 View the LLM-generated response based on real-time web content.

### ğŸ§° Troubleshooting
ğŸ’¡ 500 Error from API?
âœ”ï¸ Check if GEMINI_API_KEY and SERPER_API_KEY are set in Render.

ğŸ’¡ CORS Error?
âœ”ï¸ Add from flask_cors import CORS and CORS(app) in flask_app/app.py.

ğŸ’¡ Streamlit not receiving response?
âœ”ï¸ Make sure youâ€™re using the HTTPS Render URL in Streamlit code.


## ğŸ›¡ï¸ License

This project is open-source under the MIT License.

## ğŸ“© Contact & Contributions

ğŸ”¹ Feel free to fork this repo & contribute!

ğŸ”¹ Found a bug? Create an issue on GitHub.

ğŸ”¹ Questions? Reach out via email: venkatsaimacha123@gmail.com

ğŸš€ Built with â¤ï¸ using Flask, Streamlit & Gemini AI ğŸš€

